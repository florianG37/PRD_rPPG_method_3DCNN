{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a new rPPG method\n",
    "\n",
    "## Part 2 : Notebook for the prediction of the 3D-CNN model\n",
    "\n",
    "This jupyter notebook file complements the \"Train_3DCNN_model_BPM.ipynb\" file. In this file, we can test the model predictions on real videos and highlight logic of the future implementation into the pyVHR framework. ([Link](https://ieeexplore.ieee.org/document/9272290)) ([GitHub](https://github.com/phuselab/pyVHR))\n",
    "\n",
    "This file is based on the implementation described in the following article :\n",
    "Frédéric Bousefsaf, Alain Pruski, Choubeila Maaoui, 3D convolutional neural networks for remote pulse rate measurement and mapping from facial video, Applied Sciences, vol. 9, n° 20, 4364 (2019). ([Link](https://www.mdpi.com/2076-3417/9/20/4364)) ([GitHub](https://github.com/frederic-bousefsaf/ippg-3dcnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "Previously , you have to install theses python librairies :\n",
    "* tensorflow\n",
    "* matplotlib\n",
    "* scipy\n",
    "* numpy\n",
    "* opencv-python\n",
    "* Copy\n",
    "* pyVHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#RUN ON CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "#Tensorflow/KERAS\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "# Numpy / Matplotlib / OpenCV / Scipy / Copy\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.stats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from copy import copy\n",
    "\n",
    "#pyVHR\n",
    "from pyVHR.signals.video import Video\n",
    "from pyVHR.datasets.dataset import Dataset\n",
    "from pyVHR.datasets.dataset import datasetFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the video & pyVHR processing\n",
    "\n",
    "\n",
    "In the pyVHR framework, we work on a processed video. The processing consists of detecting and extracting an area of interest, in order to apply our rPPGs methods on relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Video object\n",
    "def extractionROI(videoFilename):\n",
    "    video = Video(videoFilename)\n",
    "    video.getCroppedFaces(detector='dlib', extractor='skvideo')\n",
    "    video.setMask(typeROI='skin_adapt',skinThresh_adapt=0.20)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "Load model & classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def loadmodel(MODEL_PATH):\n",
    "    # load data in files\n",
    "    model = model_from_json(open(f'{MODEL_PATH}/model_conv3D.json').read())\n",
    "    model.load_weights(f'{MODEL_PATH}/weights_conv3D.h5')\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # define the frequencies // output dimension (number of classes used during training)\n",
    "    freq_BPM = np.linspace(55, 240, num=model.output_shape[1]-1)\n",
    "    freq_BPM = np.append(freq_BPM, -1)     # noise class\n",
    "    return model, freq_BPM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting videoframes to a single channel array\n",
    "\n",
    "Select one channel for making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LOAD DATA\n",
    "def convertVideoToTable(video,model, startFrame):\n",
    "    imgs = np.zeros(shape=(model.input_shape[1], video.cropSize[0], video.cropSize[1], 1))\n",
    "\n",
    "    # channel extraction\n",
    "    if (video.cropSize[2]<3):\n",
    "        IMAGE_CHANNELS = 1\n",
    "    else:\n",
    "        IMAGE_CHANNELS = video.cropSize[2]\n",
    "\n",
    "    # load images (imgs contains the whole video)\n",
    "    for j in range(0, model.input_shape[1]):\n",
    "\n",
    "        if (IMAGE_CHANNELS==3):\n",
    "            temp = video.faces[j + startFrame]/255\n",
    "            temp = temp[:,:,1]      # only the G component is currently used\n",
    "        else:\n",
    "            temp = video.faces[j + startFrame] / 255\n",
    "\n",
    "        imgs[j] = np.expand_dims(temp, 2)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formating Video\n",
    "\n",
    "Realization of a catagraphy of predictions on the video.\n",
    "This function formats the video in several sets of tests, in order to make multiple predictions. The sum of these predictions is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatingDataTest(video, model, imgs, freq_BPM, stepX, stepY):\n",
    "    \n",
    "    # output - sum of predictions\n",
    "    predictions = np.zeros(shape=(len(freq_BPM)))\n",
    "    \n",
    "    # Displacement on the x axis\n",
    "    iterationX = 0\n",
    "    # Our position at n + 1 on the X axis\n",
    "    axisX = model.input_shape[3]\n",
    "    \n",
    "    # width of video\n",
    "    width = video.cropSize[1]\n",
    "    # height of video\n",
    "    height = video.cropSize[0]\n",
    "    \n",
    "    # Browse the X axis\n",
    "    while axisX < width:\n",
    "        # Displacement on the y axis\n",
    "        axisY = model.input_shape[2]\n",
    "        # Our position at n + 1 on the Y axis\n",
    "        iterationY = 0\n",
    "        # Browse the Y axis\n",
    "        while axisY < height:\n",
    "            \n",
    "            # Start position\n",
    "            x1 = iterationX * stepX\n",
    "            y1 = iterationY * stepY\n",
    "            \n",
    "            # End position\n",
    "            x2 = x1 + model.input_shape[3]\n",
    "            y2 = y1 + model.input_shape[2]\n",
    "            \n",
    "            # Cutting \n",
    "            faceCopy = copy(imgs[0:model.input_shape[1],x1:x2,y1:y2,:])\n",
    "            \n",
    "            # randomize pixel locations\n",
    "            for j in range(model.input_shape[1]):\n",
    "                temp = copy(faceCopy[j,:,:,:])\n",
    "                np.random.shuffle(temp)\n",
    "                faceCopy[j] = temp\n",
    "            \n",
    "            # Checks the validity of cutting\n",
    "            if(np.shape(faceCopy)[1] == model.input_shape[3] and np.shape(faceCopy)[2] == model.input_shape[2]):\n",
    "                # prediction on the cut part\n",
    "                xtest = faceCopy - np.mean(faceCopy)\n",
    "                predictions = predictions + getPrediction(model,freq_BPM,xtest)\n",
    "            \n",
    "            # increments\n",
    "            axisY = y2 + model.input_shape[2]\n",
    "            iterationY = iterationY +1\n",
    "        # increments    \n",
    "        axisX = x2 + model.input_shape[3]\n",
    "        iterationX = iterationX + 1\n",
    "        \n",
    "    return predictions        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a prediction\n",
    "\n",
    "Use the model to make prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(model,freq_BPM, xtest):\n",
    "    idx =0\n",
    "    maxi =0\n",
    "    # model.predict\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(xtest, 0))\n",
    "    h = model(input_tensor)\n",
    "    h = h.numpy() \n",
    "    # convert prediction to binary\n",
    "    res = np.zeros(shape=(76))\n",
    "    idx = getIdx(h[0])\n",
    "    res[idx] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the index of the maximum value of a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdx(h):\n",
    "    idx =0\n",
    "    maxi =-1\n",
    "    for i in range(0, len(h)):\n",
    "        if maxi < h[i]:\n",
    "            idx = i\n",
    "            maxi = h[i]\n",
    "    return idx  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the label associated with the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClass(h, freq_BPM, interval): \n",
    "    # index in the list\n",
    "    iterator = 0\n",
    "    # maximum value of an interval\n",
    "    sum_max = -1\n",
    "    # index of maximum value of an interval\n",
    "    idx_max = 0\n",
    "    # security against list out of range problems\n",
    "    out_of_range = len(freq_BPM) -1\n",
    "    \n",
    "    # Calculating the sum of all intervals\n",
    "    while iterator < (len(h)- interval - 1):\n",
    "        # value of studied interval\n",
    "        sum_interval = 0\n",
    "        # representative index of value of studied interval\n",
    "        idx_interval = iterator+ int(interval/2)\n",
    "        \n",
    "        # Calculates variables\n",
    "        for j in range(interval):\n",
    "            sum_interval = sum_interval + h[iterator + j]\n",
    "        \n",
    "        # Case where value of the studied interval equal to the value of the maximum interval\n",
    "        if sum_interval == sum_max and sum_interval != 0:\n",
    "            # Decision based on representative indexes\n",
    "            if(h[idx_interval] > h[idx_max]):\n",
    "                sum_max = sum_interval\n",
    "                idx_max = idx_interval\n",
    "            # Decision based on neighbors of representative indexes    \n",
    "            elif(h[idx_interval] == h[idx_max]):\n",
    "                sum_max, idx_max = study_neighborhoods(h, sum_max,sum_interval, idx_max, idx_interval, out_of_range)\n",
    "\n",
    "        # Case where the studied interval is better than the maximum interval                \n",
    "        elif (sum_interval > sum_max):\n",
    "            sum_max = sum_interval\n",
    "            idx_max = idx_interval\n",
    "        #increment    \n",
    "        iterator = iterator +1\n",
    "        \n",
    "    # return bpm value   \n",
    "    return freq_BPM[idx_max] \n",
    "\n",
    "def study_neighborhoods(h, sum_max,sum_interval, idx_max, idx_interval, out_of_range):\n",
    "    # Decision statue\n",
    "    find = False\n",
    "    # Neighborhood degree\n",
    "    var = 1\n",
    "    # intervals according to the degree of neighborhood\n",
    "    sum_var_max = h[idx_max]\n",
    "    sum_var_interval = h[idx_interval]\n",
    "                \n",
    "    # Study of neighborhood intervals\n",
    "    while find is not True:\n",
    "                    \n",
    "        if(idx_interval + var < out_of_range):\n",
    "            sum_var_interval = sum_var_interval + h[idx_interval + var]\n",
    "            \n",
    "        if(idx_interval - var >= 0):\n",
    "            sum_var_interval = sum_var_interval + h[idx_interval - var]\n",
    "            \n",
    "        if(idx_max + var < out_of_range):\n",
    "            sum_var_max = sum_var_max + h[idx_max + var]\n",
    "            \n",
    "        if(idx_max - var >= 0):\n",
    "            sum_var_max = sum_var_max + h[idx_max - var]\n",
    "                       \n",
    "        if(sum_var_max < sum_var_interval):\n",
    "            sum_max = sum_interval\n",
    "            idx_max = idx_interval\n",
    "            find =True\n",
    "            \n",
    "        if(sum_var_max > sum_var_interval):\n",
    "            find =True\n",
    "            \n",
    "        if(var > 10):\n",
    "            find = True  \n",
    "        else :\n",
    "            var = var + 1\n",
    "        \n",
    "    return sum_max, idx_max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a prediction\n",
    "\n",
    "Function to make prediction on veritable data (150 first frames only in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4246dbf27e64c488e19c09b6eee26e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame', max=1533, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   0.   1.   0.   1.   3.   3.   2.   4.  13.   1.   3.   1.\n",
      "   0.   4.  11.   0.   0.   0.   0.   0.   2.   0.   0.   0.   0.   0.\n",
      "   2.   1.   3.   0.   1.   0.   0.   2.   0.   0.   0.   0.  21.   0.\n",
      "   0.   0.   0.   0.   0.   4.   0.   0.   0.   0.   0.   0.   3.   2.\n",
      "   0.   0.   0.   0.   0.   0.   1.   0.   0.   0.   0.   4.   1.  17.\n",
      "   1.   0.   0.   0.   0. 173.]\n",
      "BPM frequency estimated = 87.5\n"
     ]
    }
   ],
   "source": [
    "videoFilename = \"./UBFC/DATASET_2/subject1/vid.avi\"  #video to be processed path\n",
    "modelFilename = \"./final_script/model/\"   #model path \n",
    "\n",
    "def makePrediction(videoFilename, modelFilename):\n",
    "    # ROI EXTRACTION\n",
    "    video = extractionROI(videoFilename)\n",
    "    # print ROI EXTRACTION\n",
    "    video.showVideo()  \n",
    "    #Load the model\n",
    "    model, freq_BPM = loadmodel(modelFilename)\n",
    "    #extract Green channel or Black & whrite channel\n",
    "    framesOneChannel = convertVideoToTable(video,model,0)\n",
    "    #Data preparation \n",
    "    Xstep = 5\n",
    "    Ystep = 5\n",
    "    prediction = formatingDataTest(video, model, framesOneChannel, freq_BPM, Xstep, Ystep)\n",
    "    print(prediction)\n",
    "    bpm = getClass(prediction, freq_BPM, 6)\n",
    "    return bpm\n",
    "\n",
    "\n",
    "print('BPM frequency estimated = ' + str(makePrediction(videoFilename, modelFilename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation test on veritable data\n",
    "\n",
    "Test on 150 first frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e936d4a5871d4ca1b37d164deb4bfa4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame', max=1533, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   1.   5.   3.   1.   0.   1.   1.   5.  21.   3.   5.   2.\n",
      "   3.   5.  12.   0.   2.   0.   0.   0.   0.   2.   0.   0.   0.   0.\n",
      "   0.   2.   1.   0.   0.   0.   0.   3.   0.   0.   0.   1.  31.   0.\n",
      "   0.   0.   1.   0.   0.   3.   0.   0.   0.   0.   0.   0.   1.   1.\n",
      "   0.   1.   0.   1.   0.   0.   1.   0.   0.   0.   2.   3.   1.  13.\n",
      "   2.   0.   0.   0.   0. 145.]\n",
      "Prediction Video 1 : 87.5\n",
      "GT Video 1 : 92.5\n",
      "ABS DIFF Video 1 : 5.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c4a19c456e43a2a8cf7b02e72eb440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='frame', max=1984, min=1), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   0.   1.   0.   1.   4.   0.   0.   0.   0.   0.   0.   0.   1.\n",
      "   2.   0.   1.   0.   0.   0.   0.   0.   2.   9.   1.   1.   1.   2.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   1.\n",
      "   0.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.   0.   0.\n",
      "   0.   0.   1.   0.   0. 132.]\n",
      "Prediction Video 2 : 117.5\n",
      "GT Video 2 : 115.0\n",
      "ABS DIFF Video 2 : 2.5\n"
     ]
    }
   ],
   "source": [
    "# video filenames\n",
    "videoFilenames = [\"./UBFC/DATASET_2/subject1/vid.avi\", \"./UBFC/DATASET_2/subject33/vid.avi\"]\n",
    "# Ground Truth (GT) filenanmes\n",
    "GT = [\"./UBFC/DATASET_2/subject1/ground_truth.txt\",\"./UBFC/DATASET_2/subject33/ground_truth.txt\"]\n",
    "# model filename\n",
    "modelFilename = \"./model/\"\n",
    "# load model\n",
    "model, freq_BPM = loadmodel(modelFilename)\n",
    "# load dataset of videos\n",
    "dataset = datasetFactory(\"UBFC2\")\n",
    "# Window size GT\n",
    "winSizeGT = 5      \n",
    "\n",
    "# For each videos\n",
    "for i in range(0, len(videoFilenames)):\n",
    "    # prediction by model\n",
    "    prediction = makePrediction(videoFilenames[i], modelFilename)\n",
    "    print(\"Prediction Video \"+ str(i+1) +\" : \"+ str(prediction))\n",
    "    # Reality\n",
    "    sigGT = dataset.readSigfile(GT[i])\n",
    "    bpmGT, timesGT = sigGT.getBPM(winSizeGT)\n",
    "    # Format the GT\n",
    "    bpm = np.round(bpmGT)\n",
    "    bpm = bpm - 55\n",
    "    bpm = np.round(bpm / 2.5)\n",
    "    GT_value = freq_BPM[int(bpm[2])]\n",
    "    print(\"GT Video \"+ str(i+1) +\" : \"+str(GT_value))\n",
    "    # difference\n",
    "    print(\"ABS DIFF Video \"+ str(i+1) +\" : \"+str(abs(GT_value-prediction)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
